{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6de9f4",
   "metadata": {},
   "source": [
    "# Архитектура MLP: как соединяются слои"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a5c90",
   "metadata": {},
   "source": [
    "## Реализация MLP на NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226a0aa",
   "metadata": {},
   "source": [
    "#### Пример из курса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b73995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SampleMLP:\n",
    "    def __init__(self, layer_sizes, activation='relu'):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            # Инициализация весов небольшой случайной матрицей\n",
    "            weight_matrix = np.random.randn(in_dim, out_dim) * 0.1\n",
    "            # Инициализация смещения нулями\n",
    "            bias_vector = np.zeros((1, out_dim))\n",
    "            self.W.append(weight_matrix)\n",
    "            self.b.append(bias_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43160446",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Создайте аналогичный класс MLP с активацией `sigmoid` в параметрах `__init__`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da4f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    # Допишите код MLP\n",
    "    def __init__(self, layer_sizes, activation='sigmoid'):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            # Инициализация весов небольшой случайной матрицей\n",
    "            weight_matrix = np.random.randn(in_dim, out_dim) * 0.1\n",
    "            # Инициализация смещения нулями\n",
    "            bias_vector = np.zeros((1, out_dim))\n",
    "            self.W.append(weight_matrix)\n",
    "            self.b.append(bias_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156fa64",
   "metadata": {},
   "source": [
    "После вычисления взвешенной суммы нейрон применяет функцию активации. Sigmoid даёт выход, плавно сжимая значения в диапазоне (0,1).\n",
    "\n",
    "Sigmoid задаётся формулой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 + np.exp(-Z))  # плавно сжимает значения к диапазону (0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72459a",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Допишите функцию активации в MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66be6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, layer_sizes, activation='sigmoid'):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.W = []      # список матриц весов\n",
    "        self.b = []      # список векторов смещений\n",
    "        # Ваша задача заполнить self.W и self.b случайными параметрами\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            weight_matrix = np.random.randn(in_dim, out_dim) * 0.1\n",
    "            bias_vector = np.zeros((1, out_dim))\n",
    "            self.W.append(weight_matrix)\n",
    "            self.b.append(bias_vector)\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        # Нужно вернуть 1 / (1 + np.exp(-Z))\n",
    "        # Ваш код здесь\n",
    "        return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f25ff",
   "metadata": {},
   "source": [
    "Осталось реализовать прямой проход. Он объединяет инициализацию и активации. \n",
    "\n",
    "На первом шаге A = X, затем итерируемся по слоям, используя веса W и смещения b. \n",
    "\n",
    "Для скрытых слоёв применяем активацию. \n",
    "\n",
    "`A = self._relu(Z)`\n",
    "\n",
    "Для последнего слоя не применяем активацию, так как она зависит от задачи (регрессия, классификация и т.п.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40103ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Демонстрация кода внутри метода forward:\n",
    "# A = X\n",
    "# for i, (W, b) in enumerate(zip(self.W, self.b)):\n",
    "#     Z = A.dot(W) + b\n",
    "#     if i < len(self.W) - 1:\n",
    "#         A = self._relu(Z)\n",
    "#     else:\n",
    "#         A = Z  # линейный выход для последнего слоя\n",
    "# return A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
